import logging
from typing import List, cast, Literal
from openai import OpenAI
from openai.types.chat import (
    ChatCompletionMessageParam,
    ChatCompletionSystemMessageParam as SysMessage,
    ChatCompletionAssistantMessageParam as AssistantMessage,
    ChatCompletionUserMessageParam as UserMessage,
)
from persons.person import Person
from session_rooms.session_room import ChatEntry
from session_rooms.session_room import System


log = logging.getLogger(__name__)


class PersonVLLM(Person):
    PERSON_TYPE = "person_vllm"

    def __init__(
        self,
        background_story: str,
        name: str,
        prompt_version: str = "v0",
        *args,
        **kwargs,
    ):
        super().__init__(background_story, name)
        self.api_base: str = kwargs.get("vllm_api_base", "http://localhost:8000/v1")
        self.model: str = kwargs.get(
            "model", "meta-llama/Llama-3.1-8B-Instruct"
        )
        self.client = OpenAI(
            api_key="EMPTY",  # vLLM usually ignores this, but required by the client
            base_url=self.api_base,
        )

        self.prompt_version = prompt_version

    def generate_answer(
        self,
        experiment_scenario: str,
        chat_list: list[ChatEntry],
        prompt_version: str | None = None,
    ):
        if prompt_version is None:
            prompt_version = self.prompt_version
        messages: List[ChatCompletionMessageParam] = self.create_prompt(
            experiment_scenario, chat_list, prompt_version
        )
        answer = self.evaluate(messages)
        return ChatEntry(entity=self, prompt=messages, answer=answer)

    def evaluate(self, messages: List[ChatCompletionMessageParam], max_new_tokens=100):
        response = self.client.chat.completions.create(
            model=self.model,
            messages=messages,
            max_tokens=max_new_tokens,
            temperature=1.0,
            top_p=0.9,
            n=1,
        )

        output = (response.choices[0].message.content or "") if response.choices else ""
        return output.strip().removeprefix("Me: ")

    # TODO: Choose the best prompt and prompt structure (should it all be in system?)
    def create_prompt(
        self, experiment_scenario: str, chat_list: List[ChatEntry], prompt_version: str
    ) -> List[ChatCompletionMessageParam]:
        """
        Creates a prompt with the past conversation in the format expected by OpenAI Chat API.
        The returned conversation is a list of entries, which follows the format described at
        https://help.openai.com/en/articles/7042661-chatgpt-api-transition-guide.

        In particular, the "role" property has 3 values, which we use as follows:
            - "system": Only used in the first / last entries to set up the person instance identity.
            - "assistant": Used for messages generated by the person instance.
            - "user": Used for messages generated by other persons. Each entry can consist of
              messages from multiple persons, by concatenating the format "{name}: {content}\n".
        """

        assert prompt_version in [
            "v0",
            "v1",
            "v2",
        ], f"Unknown prompt version {prompt_version}. Please use v0, v1 or v2."
        prompt_version_literal: Literal["v0", "v1", "v2"] = cast(
            Literal["v0", "v1", "v2"], prompt_version
        )
        conversation: List[ChatCompletionMessageParam] = super().prompt_setups(
            experiment_scenario=experiment_scenario,
            prompt_version=prompt_version_literal,
        )

        
        for chat_entry in chat_list:
            if isinstance(chat_entry.entity, System):  # System message
                conversation.append(
                    SysMessage(role="system", content=chat_entry.answer)
                )
            elif chat_entry.entity.PERSON_TYPE == self.PERSON_TYPE:  # This
                # person's message
                conversation.append(
                    AssistantMessage(
                        role="assistant",
                        content=f"Me: {chat_entry.answer}\n",
                    )
                )
            else:  # Other person's message
                # Concatenate the name and content of the other person's message
                conversation.append(
                    UserMessage(
                        role="user",
                        content=f"{chat_entry.entity.name}: {chat_entry.answer}\n",
                    )
                )
                
                





        return conversation
